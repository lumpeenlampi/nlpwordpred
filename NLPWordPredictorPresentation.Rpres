NLPWordPredictorPresentation
========================================================
author: Lumpeenlampi
date: 1.9.2018
autosize: true

Introduction
========================================================

NLPWordPredictor - an NGram based word predictor

- Based on NGrams up to 5
- Utilising "Stupid Back Off" algorithm
- Medium footprint of approx 150 MB
- Accuracy close to 20%
- Fast! - average prediction in 25 ms
- Listing of alternatives with score
- Word cloud for graphical representation
- Possibility to select lower NGRam prediction

Building of the model
========================================================
The model was built with a trainingset from Blogs, News and Twitter in english, size ~569 MB

Preprocessing
- Converting to lowercase, number and punctuation removal
- Converting to ASCII and eliminating superfluous characters
- Splitting into approx. 70 files to avoid memory problems
- Setting aside chunks (~7%) from the three sources for testing

NGram analysis
- Generation of 1, 2, 3, 4 and 5-grams with tm package
- Merging separate files into combined ngram lists with counts
- Ngram lists built with n=1, except for 5-gram (n=2; memory limit)

Classifier model building
- Calculate score for each n-gram for use with Stupid Back-Off algorithm
- Tools for purging Ngram lists by count, score, or top-3 options/n-gram
- Classifier algorithm uses Stupid Back Off for matches


Accuracy dependence for various tested models
========================================================

```{r echo=FALSE, fig.width=16, fig.height=11, fig.show="hold", fig.align="center"}
library(ggplot2)
library(gridExtra)
library(readr)
library(data.table)

log <- fread("testlog.csv") # Test log

p1 <- ggplot(log[alt==-1 & minscore < 2], aes(x=minscore, y=totalacc, colour=factor(ngrams))) + geom_point() + ggtitle("Accuracy dependence on minimum score in training set")

p2 <- ggplot(log[alt==-1 & minscore < 2], aes(x=ngrams, y=totalacc, colour=minscore)) + geom_point() + ggtitle("Accuracy dependence on ngrams in training set")

p3 <- ggplot(log[alt==-1 & minscore < 2 & ngrams==5], aes(x=minscore)) +
geom_point(aes(y=totalacc, colour="total")) +
geom_point(aes(y=toptenmatch, colour="top 10")) +
geom_point(aes(y=topthreematch, colour="top 3")) +
ggtitle("Accuracy (total, top 10, top 3) dependence on minimum score in training set")

p4 <- ggplot(log[alt==-1 & minscore < 2 & ngrams==5], aes(x=minscore)) + geom_point(aes(y=totalacc, colour="total accuracy")) +
geom_point(aes(y=blogacc, colour="blogs accuracy")) +
geom_point(aes(y=newsacc, colour="news accuracy")) +
geom_point(aes(y=twitteracc, colour="twitter accuracy")) +
ggtitle("Accuracy dependence on minimum score in training set")

p5 <- ggplot(log[alt==-1 & minscore < 2 & ngrams==5], aes(x=filesize, y=totalacc, colour=minscore)) + geom_point() + ggtitle("Accuracy relation to the size of the model")

p6 <- ggplot(log[!(is.na(id) | id=="")], aes(x=ngrams, y=totalacc, colour=id)) + geom_line() + ggtitle("Accuracy dependence on ngrams for selected models")

grid.arrange(p1, p2, p3, p4, p5, p6, nrow=2)             

```
Note: The test includes models with different parameters

Optimization of parameters
========================================================

Test tool
- Generates random input vector from test chunks
- Runs predictor n (1000) times for each input (blogs, news, twitter)
and outputs performance indicators (accuracy, time, match position, etc)
- Tests used to optimise parameters for model (count, score, top-3 ngrams)

Final choice of the parameters for the web application:
- General aim to minimize file size while keeping reasonable accuracy
- n = 5 (2-gram), 4 (3-g), 3 (4-g) and 2 (5-g), 
- minimum score =0.01
- Only top 3 options for any ngram start were maintained

Features of the algorithm
- Model size: 158 MB
- Accuracy: blogs: 17.7%, news: 21.3%, twitter:18.6%, total: 19.2%
- Match in top 3: 27,6%, match in top 10: 29.1%
- Response time: 21ms

```{r, echo=FALSE}
print(log[id=="final+alt" & ngrams==5])
```


Web application & further development
========================================================

The NLP Word predictor was embedded in a web application and can be used online via the following link: <http://...>

The application provides the possibility to evaluate operation when restricting the level of ngrams and shows the best 10 matches for the predicted word with score, and count (in the training set) as well as used n-gram. An example is shown below.

The NLP word predictor can still be improved by e.g. avoiding training data to cross sentence punctuation and including separate models that take grammar and/or topical consistency into account.

![Picture of the application](NLPWordPred.jpg)

